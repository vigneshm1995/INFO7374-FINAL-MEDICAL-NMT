{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4-4-128neuron-rmsprop0001.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "iEu-R6cQeHYR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*This Note book referenced [WuJiaocan's Github](https://github.com/WuJiaocan/tensorflow), [XueYouluo's Github](https://github.com/xueyouluo/my_seq2seq/blob/90c86bacd5cb88ad8d381de28fe3bdf8421a0036/notebooks/MyS2S.ipynb)\n",
        "\n",
        "*Major contribution of this notebook is: provided a flexible NMT network building (change of layers, cell-type, switch between bi-direction and uni-direction RNN, switch between attention mechanisms) based on Tensorflow through parameter setting"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "GuFkJ2aU_Zi5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PJiogIp9b2wl",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import codecs\n",
        "import sys\n",
        "import numpy as np\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zLFyhUb2i1Mw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# INSTRUCTION -0: RECORD PARAMETERS\n",
        "\n",
        "!! Please record all hyper parameters [HERE](https://docs.google.com/spreadsheets/d/1VgRGGDv_ynvTORz3vHtH2VgRQnyxv9qBkDkPjSpDj3c/edit?usp=sharing) **BEFORE** start traning. \n",
        "\n",
        "This is to avoid duplicated/similar experiments among our team"
      ]
    },
    {
      "metadata": {
        "id": "FHk7MJneMcOy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# INSTRUCTION-1: SET TRAINING DATASET\n",
        "\n",
        "Set NUM_EXAMPLES AND Run All Cells\n",
        "\n",
        "Time for 1 Epoch on Colab GPU for reference:\n",
        "\n",
        "1. 100,000 sentence pairs: 285s\n",
        "2.  50,000 sentence pairs: 127s"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "KEHEZvJsb2wq"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.Create Vocabulary"
      ]
    },
    {
      "metadata": {
        "id": "t5XnjFPzmAyQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"data.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9eNtsF8sNIib",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NUM_SENT = 50000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aI-cxiUvpNX1",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "src_path = 'en_clean.txt'\n",
        "tgt_path = 'fr_clean.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "rJiL1dcSYGfu",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_train_data(txt_path, num_examples):\n",
        "  text = []\n",
        "  with open(txt_path, 'r', encoding=\"utf-8\") as f:\n",
        "    for line in f.readlines():\n",
        "      line = line[7:-6]\n",
        "      text.append(line.strip('\\n'))\n",
        "    return text[:num_examples]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "AV0S3gdJYJ0L",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "src = read_train_data(src_path, NUM_SENT)\n",
        "tgt = read_train_data(tgt_path, NUM_SENT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3-sjdYzQR50n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_test_data(txt_path, num_examples = 400):\n",
        "  text = []\n",
        "  with open(txt_path, 'r', encoding=\"utf-8\") as f:\n",
        "    for line in f.readlines():\n",
        "      line = line[7:-6]\n",
        "      text.append(line.strip('\\n'))\n",
        "    return text[-num_examples:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YvaIqQxURwdy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "src_test = read_test_data(src_path)\n",
        "tgt_test = read_test_data(tgt_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "kLtCweCAzSaM",
        "outputId": "eeb2e7b1-accf-460e-8210-70647d801c82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print('size of number of source sentences from dataset for training: {}'.format(len(src)))\n",
        "print('size of number of target sentences from dataset for training: {}'.format(len(tgt)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size of number of source sentences from dataset for training: 50000\n",
            "size of number of target sentences from dataset for training: 50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sv0IiNnzSXFE",
        "colab_type": "code",
        "outputId": "61f00b6e-d81f-4137-f569-7b4c4ad5fdc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print('size of number of source sentences from dataset for testing: {}'.format(len(src_test)))\n",
        "print('size of number of target sentences from dataset for testing: {}'.format(len(tgt_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size of number of source sentences from dataset for testing: 400\n",
            "size of number of target sentences from dataset for testing: 400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lY7aR7n3p1uq",
        "colab_type": "code",
        "outputId": "a2660ec1-00ea-4009-af7f-f2db68f5327f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "# Display examples for quick check\n",
        "\n",
        "for i in range(5):\n",
        "  print(src[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " global health where do physiotherapy and rehabilitation research fit ? \n",
            " carabin \n",
            " comment on the misappropriation of bibliographical references in science . the example of anti aging medicine \n",
            " anti aging medicine , a science based , essential medicine \n",
            " underwater dive in fresh water complicated by a cardiorespiratory arrest on obstructive shock \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lIa237Bxp_OP",
        "colab_type": "code",
        "outputId": "3837ab21-b48c-497a-ee63-daf72c626ce8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print(tgt[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " la place des cheveux et des poils dans les rituels et le sacre \n",
            " les carabins \n",
            " du detournement des references bibliographiques en science . l exemple de la medecine anti age \n",
            " la medecine anti age , une medecine scientifique , indispensable \n",
            " plongee subaquatique en eau douce compliquee d un arret cardiorespiratoire sur choc obstructif \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "anWnM8YtASZK",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import codecs\n",
        "import collections\n",
        "from operator import itemgetter\n",
        "\n",
        "def create_vocab(RAW_DATA, VOCAB_OUTPUT):\n",
        "    counter = collections.Counter()\n",
        "\n",
        "    for line in RAW_DATA:\n",
        "        for word in line.strip().lower().split():\n",
        "            counter[word] += 1\n",
        "\n",
        "    sorted_word_to_cnt = sorted(counter.items(), key=itemgetter(1), reverse=True)\n",
        "    sorted_words = [x[0] for x in sorted_word_to_cnt]\n",
        "\n",
        "    sorted_words =  ['<pad>'] + ['<sos>'] + ['<eos>'] + ['<unk>'] + sorted_words \n",
        "\n",
        "    with codecs.open(VOCAB_OUTPUT, \"w\", encoding=\"utf-8\") as file_output:\n",
        "        for word in sorted_words:\n",
        "            file_output.write(word + \"\\n\")\n",
        "    return sorted_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "n0GiEHwwBktl",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocab_src = create_vocab(src, 'vocab.en')\n",
        "vocab_tgt = create_vocab(tgt, 'vocab.fr')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "t27JbnSEB0Ld",
        "outputId": "54fe163d-c2a7-49e6-eb4a-1fd9c767f8f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "vocab_size_src = len(vocab_src)\n",
        "vocab_size_tgt = len(vocab_tgt)\n",
        "\n",
        "print('size of source vocab {}'.format(vocab_size_src))\n",
        "print('size of target vocab {}'.format(vocab_size_tgt))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size of source vocab 28711\n",
            "size of target vocab 35019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Gh72SwWYpf-s",
        "colab_type": "code",
        "outputId": "f7bc24b7-958d-42c6-ed17-c3b7149e0cb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(vocab_src[-5:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['homolateral', 'peritonsillar', 'radt', 'lobbying', 'mediacalcosis']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4jD75jN6pt2U",
        "colab_type": "code",
        "outputId": "1b65d889-ece8-4f83-d0a1-a6777215ec97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(vocab_tgt[-5:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['respective', 'periamygdalien', 'bachelot', 'lobbying', 'mediacalcose']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Zfibo4tGC2y1"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.Convert Text to Numbers"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "TLY75347DdUa",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import codecs\n",
        "import sys\n",
        "\n",
        "def text_to_int(RAW_DATA, VOCAB, OUTPUT_DATA):\n",
        "\n",
        "  with codecs.open(VOCAB, \"r\", encoding=\"utf-8\") as f_vocab:\n",
        "      vocab = [w.strip() for w in f_vocab.readlines()]\n",
        "      word_to_id = {k:v for (k,v) in zip(vocab, range(len(vocab)))}\n",
        "\n",
        "  def get_id(word):\n",
        "      return word_to_id[word] if word in word_to_id else word_to_id[\"<unk>\"]\n",
        "\n",
        "  fout = codecs.open(OUTPUT_DATA, \"w\", encoding=\"utf-8\")\n",
        "  for line in RAW_DATA:\n",
        "      words = line.strip().split() + [\"<eos>\"]\n",
        "\n",
        "      out_line = \" \".join([str(get_id(w)) for w in words]) + \"\\n\"\n",
        "      fout.write(out_line)\n",
        "  fout.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3ZQkUw4SEZvS",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "text_to_int(src, 'vocab.en', 'train.en')\n",
        "text_to_int(tgt, 'vocab.fr', 'train.fr')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Nqjb9gLwb2ww"
      },
      "cell_type": "markdown",
      "source": [
        "### 4. Create Training Dataset"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "q4-E4no-b2wx",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def MakeDataset(file_path):\n",
        "    dataset = tf.data.TextLineDataset(file_path)\n",
        "    # split by space\n",
        "    dataset = dataset.map(lambda string: tf.string_split([string]).values)\n",
        "    # convert string to number\n",
        "    dataset = dataset.map(\n",
        "        lambda string: tf.string_to_number(string, tf.int32))\n",
        "    # calc # word/sentence and put in dataset with sentence\n",
        "    dataset = dataset.map(lambda x: (x, tf.size(x)))\n",
        "    return dataset\n",
        "\n",
        "def MakeSrcTrgDataset(src_path, trg_path, batch_size):\n",
        "\n",
        "    src_data = MakeDataset(src_path)\n",
        "    trg_data = MakeDataset(trg_path)\n",
        "    #   ds[0][0]source sentence\n",
        "    #   ds[0][1]len of source sentence\n",
        "    #   ds[1][0]target sentence\n",
        "    #   ds[1][1]len of target sentence\n",
        "    dataset = tf.data.Dataset.zip((src_data, trg_data))\n",
        "\n",
        "    # delete empty and super-long sentence\n",
        "    def FilterLength(src_tuple, trg_tuple):\n",
        "        ((src_input, src_len), (trg_label, trg_len)) = (src_tuple, trg_tuple)\n",
        "        src_len_ok = tf.logical_and(\n",
        "            tf.greater(src_len, 1), tf.less_equal(src_len, MAX_LEN))\n",
        "        trg_len_ok = tf.logical_and(\n",
        "            tf.greater(trg_len, 1), tf.less_equal(trg_len, MAX_LEN))\n",
        "        return tf.logical_and(src_len_ok, trg_len_ok)\n",
        "    dataset = dataset.filter(FilterLength)\n",
        "    \n",
        "    #   1.trg_input: \"<sos> X Y Z\"\n",
        "    #   2.trg_label: \"X Y Z <eos>\"\n",
        "    #   file: \"X Y Z <eos>\", need to produce \"<sos> X Y Z\" and add to dataset\n",
        "    def MakeTrgInput(src_tuple, trg_tuple):\n",
        "        ((src_input, src_len), (trg_label, trg_len)) = (src_tuple, trg_tuple)\n",
        "        trg_input = tf.concat([[SOS_ID], trg_label[:-1]], axis=0)\n",
        "        return ((src_input, src_len), (trg_input, trg_label, trg_len))\n",
        "    \n",
        "    dataset = dataset.map(MakeTrgInput)\n",
        "\n",
        "    dataset = dataset.shuffle(10000)\n",
        "\n",
        "    # define shape after padding\n",
        "    padded_shapes = (\n",
        "        (tf.TensorShape([None]),\n",
        "         tf.TensorShape([])), \n",
        "        (tf.TensorShape([None]),\n",
        "         tf.TensorShape([None]),\n",
        "         tf.TensorShape([]))) \n",
        "    \n",
        "    # padded_batch to pad\n",
        "    batched_dataset = dataset.padded_batch(batch_size, padded_shapes)\n",
        "    return batched_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "luDX1Q-Nb2w1"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.Define NMT"
      ]
    },
    {
      "metadata": {
        "id": "rGhFp7rbBadA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def single_rnn_cell(cell_name, hid_size, keep_prob):\n",
        "    if cell_name == \"GRU\":\n",
        "        cell = tf.contrib.rnn.GRUCell(hid_size)\n",
        "    elif cell_name == \"LSTM\":\n",
        "        cell = tf.contrib.rnn.LSTMCell(hid_size)\n",
        "    elif cell_name == \"BASIC\":\n",
        "        cell = tf.contrib.rnn.BasicRNNCell(hid_size)\n",
        "        \n",
        "    if keep_prob < 1.0:\n",
        "      cell = tf.contrib.rnn.DropoutWrapper(\n",
        "            cell=cell,\n",
        "            input_keep_prob=keep_prob,\n",
        "            output_keep_prob=keep_prob)\n",
        "    \n",
        "    return cell\n",
        "\n",
        "\n",
        "def multi_rnn_cell(cell_name, hid_size, num_layers, keep_prob):\n",
        "    cells = []\n",
        "    for _ in range(num_layers):\n",
        "        cell = single_rnn_cell(cell_name, hid_size, keep_prob)\n",
        "        cells.append(cell)\n",
        "    \n",
        "    if len(cells) > 1:\n",
        "        final_cell = tf.contrib.rnn.MultiRNNCell(cells=cells)\n",
        "    else:\n",
        "        final_cell = cells[0]\n",
        "    return final_cell\n",
        "  \n",
        "  \n",
        "def single_biRNN_pair(cell_name, hid_size, keep_prob):\n",
        "    if cell_name == \"bi-GRU\":\n",
        "      enc_cell_fw = single_rnn_cell('GRU', hid_size, keep_prob)\n",
        "      enc_cell_bw = single_rnn_cell('GRU', hid_size, keep_prob)\n",
        "    elif cell_name == \"bi-LSTM\":\n",
        "      enc_cell_fw = single_rnn_cell('LSTM', hid_size, keep_prob)\n",
        "      enc_cell_bw = single_rnn_cell('LSTM', hid_size, keep_prob)\n",
        "    return enc_cell_fw, enc_cell_bw\n",
        "    \n",
        "def multi_biRNN_pair(cell_name, hid_size, num_layers, keep_prob):\n",
        "    stacked_biRNN_fw = []\n",
        "    stacked_biRNN_bw = []\n",
        "    for _ in range(num_layers):\n",
        "        enc_cell_fw, enc_cell_bw = single_biRNN_pair(cell_name, hid_size, keep_prob)\n",
        "        stacked_biRNN_fw.append(enc_cell_fw)\n",
        "        stacked_biRNN_bw.append(enc_cell_bw)\n",
        "    \n",
        "    if len(stacked_biRNN_fw) > 1:\n",
        "        final_stacked_biRNN_fw = tf.contrib.rnn.MultiRNNCell(cells=stacked_biRNN_fw)\n",
        "        final_stacked_biRNN_bw = tf.contrib.rnn.MultiRNNCell(cells=stacked_biRNN_bw)\n",
        "    else:\n",
        "        final_stacked_biRNN_fw = stacked_biRNN_fw[0]\n",
        "        final_stacked_biRNN_bw = stacked_biRNN_bw[0]\n",
        "    return final_stacked_biRNN_fw, final_stacked_biRNN_bw"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "oFDKNSELb2w1",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NMTModel(object):\n",
        "  \"\"\"\n",
        "  defind the nmt model\n",
        "  \n",
        "  \"\"\"\n",
        "  # define variables needed by nmt\n",
        "  def __init__(self, \n",
        "               dec_layer, \n",
        "               enc_layer,\n",
        "               dec_cell_name, \n",
        "               enc_cell_name,\n",
        "               optimizer, \n",
        "               lr,\n",
        "               hid_size, \n",
        "               attention,\n",
        "               drop_out):\n",
        "    \n",
        "    self.dec_cell_name = dec_cell_name\n",
        "    self.enc_cell_name = enc_cell_name\n",
        "    self.dec_layer = dec_layer\n",
        "    self.enc_layer = enc_layer\n",
        "    self.attention = attention\n",
        "    \n",
        "    self.hid_size = hid_size\n",
        "    self.opt = optimizer\n",
        "    self.lr = lr\n",
        "    \n",
        "    self.keep_prob = 1.0 - drop_out\n",
        "\n",
        "    # EMBEDDING SETUP\n",
        "    \n",
        "    self.src_embedding = tf.get_variable(\n",
        "          \"src_emb\", [SRC_VOCAB_SIZE, self.hid_size])\n",
        "    self.trg_embedding = tf.get_variable(\n",
        "          \"trg_emb\", [TRG_VOCAB_SIZE, self.hid_size])\n",
        "\n",
        "      # define variables for softmax layer\n",
        "    if SHARE_EMB_AND_SOFTMAX:\n",
        "         self.softmax_weight = tf.transpose(self.trg_embedding)\n",
        "    else:\n",
        "         self.softmax_weight = tf.get_variable(\n",
        "             \"weight\", [self.hid_size, TRG_VOCAB_SIZE])\n",
        "    self.softmax_bias = tf.get_variable(\n",
        "          \"softmax_bias\", [TRG_VOCAB_SIZE])\n",
        "     \n",
        "  # calculate forward graph\n",
        "  # src_input, src_size, trg_input, trg_label, trg_size are from MakeSrcTrgDataset\n",
        "  \n",
        "  def forward(self, src_input, src_size, trg_input, trg_label, trg_size):\n",
        "      batch_size = tf.shape(src_input)[0]\n",
        "      \n",
        "      # *************************\n",
        "      # **** EMBEDDING SCOPE ****\n",
        "      # *************************\n",
        "      \n",
        "      with tf.variable_scope(\"Embeddings\"):\n",
        "\n",
        "        # convert word_int input to embeddings\n",
        "        src_emb = tf.nn.embedding_lookup(self.src_embedding, src_input)\n",
        "        trg_emb = tf.nn.embedding_lookup(self.trg_embedding, trg_input)\n",
        "\n",
        "        # set drop_out rate\n",
        "        src_emb = tf.nn.dropout(src_emb, self.keep_prob)\n",
        "        trg_emb = tf.nn.dropout(trg_emb, self.keep_prob)\n",
        "\n",
        "      # *************************\n",
        "      # ***** ENCODER SCOPE *****\n",
        "      # *************************\n",
        "\n",
        "      with tf.variable_scope(\"encoder\"):\n",
        "        \n",
        "        if not 'bi' in self.enc_cell_name:\n",
        "        \n",
        "          enc_cell = multi_rnn_cell(self.enc_cell_name, \n",
        "                                    self.hid_size, \n",
        "                                    self.enc_layer, \n",
        "                                    self.keep_prob)\n",
        "          enc_outputs, enc_state = tf.nn.dynamic_rnn(enc_cell, \n",
        "                                                     inputs=src_emb, \n",
        "                                                     sequence_length=src_size, \n",
        "                                                     dtype=tf.float32) \n",
        "        \n",
        "        else:\n",
        "          \n",
        "          stacked_biRNN_fw, stacked_biRNN_bw = multi_biRNN_pair(self.enc_cell_name, \n",
        "                                                                self.hid_size, \n",
        "                                                                self.enc_layer, \n",
        "                                                                self.keep_prob)\n",
        "          enc_outputs, enc_state = tf.nn.bidirectional_dynamic_rnn(cell_fw = stacked_biRNN_fw,\n",
        "                                                                   cell_bw = stacked_biRNN_bw,\n",
        "                                                                   inputs = src_emb,\n",
        "                                                                   sequence_length = src_size,\n",
        "                                                                   dtype = tf.float32)\n",
        "          \n",
        "          # concatenate two outputs of LSTM cell as 1 tensor\n",
        "          # enc_outputs = (output_fw, output_bw)\n",
        "          enc_outputs = tf.concat([enc_outputs[0], enc_outputs[1]], -1)\n",
        "          \n",
        "    \n",
        "      # *************************\n",
        "      # ***** DECODER SCOPE *****\n",
        "      # *************************\n",
        "      \n",
        "      with tf.variable_scope(\"decoder\"):\n",
        "        \n",
        "        dec_cell = multi_rnn_cell(self.dec_cell_name, self.hid_size, self.dec_layer, self.keep_prob)\n",
        "    \n",
        "    \n",
        "        # OPTIONS FOR ATTENTION MECHANISM\n",
        "        if self.attention == 'Bahdanau':\n",
        "        \n",
        "          attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(\n",
        "                  self.hid_size, \n",
        "                  enc_outputs,\n",
        "                  memory_sequence_length = src_size)\n",
        "          \n",
        "        if self.attention == 'Luong':\n",
        "\n",
        "          attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n",
        "                  self.hid_size,\n",
        "                  enc_outputs,\n",
        "                  memory_sequence_length=src_size)\n",
        "\n",
        "        # ATTENTION WRAPPER: \n",
        "        # wrap dec_cell and attention mechanisim\n",
        "        attention_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
        "                dec_cell, \n",
        "                attention_mechanism,\n",
        "                attention_layer_size=self.hid_size)\n",
        "\n",
        "        # use attention_cell and dynamic_rnn construct decoder\n",
        "        # here relay totally on attention as the information source\n",
        "        dec_outputs, _ = tf.nn.dynamic_rnn(\n",
        "                attention_cell, trg_emb, trg_size, dtype=tf.float32)\n",
        "\n",
        "        \n",
        "      # ************************\n",
        "      # ***** OPTIMIZATION *****\n",
        "      # ************************\n",
        "      \n",
        "      # LOSS/LOG PERPLEXITY\n",
        "      output = tf.reshape(dec_outputs, [-1, HIDDEN_SIZE])\n",
        "      logits = tf.matmul(output, self.softmax_weight) + self.softmax_bias\n",
        "      loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "          labels=tf.reshape(trg_label, [-1]), logits=logits)\n",
        "\n",
        "      # set padding weight as 0 when calc average loss\n",
        "      label_weights = tf.sequence_mask(\n",
        "          trg_size, maxlen=tf.shape(trg_label)[1], dtype=tf.float32)\n",
        "      label_weights = tf.reshape(label_weights, [-1])\n",
        "      cost = tf.reduce_sum(loss * label_weights)\n",
        "      cost_per_token = cost / tf.reduce_sum(label_weights)\n",
        "\n",
        "      # define backprop\n",
        "      trainable_variables = tf.trainable_variables()\n",
        "\n",
        "      # OPTIONS FOR OPTIMIZER\n",
        "      # define optimization method/steps\n",
        "      grads = tf.gradients(cost / tf.to_float(batch_size),\n",
        "                           trainable_variables)\n",
        "      \n",
        "      grads, _ = tf.clip_by_global_norm(grads, clip_norm = 5)\n",
        "\n",
        "      if self.opt == 'adam':\n",
        "        optimizer = tf.train.AdamOptimizer(learning_rate = self.lr)\n",
        "      \n",
        "      elif self.opt == 'sgd':        \n",
        "        optimizer = tf.train.GradientDescentOptimizer(learning_rate = self.lr)\n",
        "        \n",
        "      elif self.opt == 'rmsprop':     \n",
        "        optimizer = tf.train.RMSPropOptimizer(learning_rate = self.lr)\n",
        "      \n",
        "      train_op = optimizer.apply_gradients(zip(grads, trainable_variables))\n",
        "      \n",
        "      return cost_per_token, train_op"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "_U7MgEmib2w4"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.Training"
      ]
    },
    {
      "metadata": {
        "id": "PNOXSsRX4lEP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run_epoch(session, cost_op, train_op, saver, step):\n",
        "    while True:\n",
        "        try:\n",
        "            # execute train_op and calc loss\n",
        "            cost, _ = session.run([cost_op, train_op])\n",
        "            if step % 10 == 0:\n",
        "                print(\"After %d steps, per token cost is %.3f\" % (step, cost))\n",
        "            # save checkpoint per 200 steps\n",
        "            if step % 200 == 0:\n",
        "                saver.save(session, CHECKPOINT_PATH, global_step=step)\n",
        "            step += 1\n",
        "        except tf.errors.OutOfRangeError:\n",
        "            break\n",
        "    return step"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rjRtDQUd41BS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#INSTRUCTION-2: SET TRAINING HYPER PARAMETERS\n",
        "\n",
        "1. Normally just leave following things as they are, unless changed training dataset or dataset size:\n",
        "  * SRC_TRAIN_DATA,\n",
        "  * TRG_TRAIN_DATA,\n",
        "  * SRC_VOCAB_SIZE\n",
        "  * TRG_VOCAB_SIZE\n",
        "\n",
        "2. Need to change CHECKPOINT_PATH each time for a training to distinguish different training setting (for easier recording)\n",
        "\n",
        "3. Following Prameters can be tuned for research and experiment purpose:\n",
        "\n",
        "  * HIDDEN_SIZE (# INTEGER)\n",
        "  * DECODER_LAYERS (# INTEGER)\n",
        "  * DECODER_CELL_TYPE (OPTIONS: 'LSTM', 'GRU', 'BASIC')\n",
        "  * ENCODER_LAYERS (# INTEGER)\n",
        "  * ENCODER_CELL_TYPE (OPTIONS: 'LSTM', 'GRU', 'BASIC', 'bi-LSTM', 'bi-GRU')\n",
        "  * ATTENTION ('Luong', 'Bahdanau')\n",
        "  * DROP_OUT (0~1.0)\n",
        "  * OPTIMIZER (OPTIONS: 'adam', 'sgd', 'rmsprop')\n",
        "  * LEARNING_RATE (0.0001 ~ 0.1)\n",
        "  * NUM_EPOCH (#INTEGER: dont' use big number as it consumes time, could keep consistent across all experiments to compare whose loss decreased the most in certain epochs)\n",
        "  * BATCH_SIZE (#INTEGER: 32, 64, 128, 256...)\n",
        "  \n",
        "  \n",
        "  **NOTICE: ALL PARAM NAMES ARE CASE SENSITIVE**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "_J2_kj9vb2w4",
        "outputId": "ee5ba95b-3de1-4ce0-f10f-e5d0d2169e0f",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 14929
        }
      },
      "cell_type": "code",
      "source": [
        "CHECKPOINT_PATH = \"./ckpt-exp08/google-brain-gru-128size\"  \n",
        "\n",
        "HIDDEN_SIZE = 128\n",
        "DECODER_LAYERS = 4                    # Num_layer for decoder LSTM\n",
        "DECODER_CELL_TYPE = 'LSTM'\n",
        "ENCODER_LAYERS = 4\n",
        "ENCODER_CELL_TYPE = 'bi-LSTM'\n",
        "ATTENTION = 'Bahdanau'\n",
        "OPTIMIZER = 'rmsprop'\n",
        "DROPOUT = 0.2\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "NUM_EPOCH = 20\n",
        "\n",
        "\n",
        "SRC_TRAIN_DATA = \"train.en\"\n",
        "TRG_TRAIN_DATA = \"train.fr\"\n",
        "SRC_VOCAB_SIZE = vocab_size_src       \n",
        "TRG_VOCAB_SIZE = vocab_size_tgt \n",
        "SHARE_EMB_AND_SOFTMAX = True           # share weights between softmax layer and embedding layer\n",
        "MAX_LEN = 100   # max length of a sentence\n",
        "SOS_ID  = 1    # <sos> ID in target vocab\n",
        "\n",
        "import time\n",
        "def main():\n",
        "  \n",
        "    initializer = tf.random_uniform_initializer(-0.05, 0.05)\n",
        "    \n",
        "    tf.reset_default_graph()\n",
        "\n",
        "    with tf.variable_scope(\"nmt_model\", reuse=None, \n",
        "                           initializer=initializer):\n",
        "        train_model = NMTModel(\n",
        "                dec_layer = DECODER_LAYERS, \n",
        "                enc_layer = ENCODER_LAYERS,\n",
        "                dec_cell_name =  DECODER_CELL_TYPE,\n",
        "                enc_cell_name = ENCODER_CELL_TYPE,\n",
        "                optimizer = OPTIMIZER, \n",
        "                lr = LEARNING_RATE,\n",
        "                hid_size = HIDDEN_SIZE, \n",
        "                attention = ATTENTION,\n",
        "                drop_out = DROPOUT)\n",
        "  \n",
        "    # define input data\n",
        "    data = MakeSrcTrgDataset(SRC_TRAIN_DATA, TRG_TRAIN_DATA, BATCH_SIZE)\n",
        "    iterator = data.make_initializable_iterator()\n",
        "    (src, src_size), (trg_input, trg_label, trg_size) = iterator.get_next()\n",
        " \n",
        "    # define forward graph\n",
        "    cost_op, train_op = train_model.forward(src, src_size, trg_input,\n",
        "                                            trg_label, trg_size)\n",
        "\n",
        "    # train\n",
        "    saver = tf.train.Saver()\n",
        "    tf.add_to_collection('train_op', train_op)\n",
        "    tf.add_to_collection('cost_op', cost_op)\n",
        "    step = 0\n",
        "    with tf.Session() as sess:\n",
        "        writer = tf.summary.FileWriter('logs', sess.graph)\n",
        "        writer.close()\n",
        "        \n",
        "        tf.global_variables_initializer().run()\n",
        "        for i in range(NUM_EPOCH):\n",
        "            time_start=time.time()\n",
        "            print(\"-------In iteration: %d\" % (i + 1))\n",
        "            sess.run(iterator.initializer)\n",
        "            step = run_epoch(sess, cost_op, train_op, saver, step)\n",
        "            time_end=time.time()\n",
        "            print('-------time cost',time_end-time_start,'s')\n",
        "            print('                                        ')\n",
        "            \n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From <ipython-input-22-c090c396d1f3>:63: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-21-10415cb8d94e>:5: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-21-10415cb8d94e>:49: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-22-c090c396d1f3>:93: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From <ipython-input-22-c090c396d1f3>:159: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "-------In iteration: 1\n",
            "After 0 steps, per token cost is 10.462\n",
            "After 10 steps, per token cost is 10.460\n",
            "After 20 steps, per token cost is 10.456\n",
            "After 30 steps, per token cost is 10.452\n",
            "After 40 steps, per token cost is 10.446\n",
            "After 50 steps, per token cost is 10.438\n",
            "After 60 steps, per token cost is 10.426\n",
            "After 70 steps, per token cost is 10.391\n",
            "After 80 steps, per token cost is 10.188\n",
            "After 90 steps, per token cost is 8.836\n",
            "After 100 steps, per token cost is 8.031\n",
            "After 110 steps, per token cost is 7.419\n",
            "After 120 steps, per token cost is 7.213\n",
            "After 130 steps, per token cost is 7.021\n",
            "After 140 steps, per token cost is 6.965\n",
            "After 150 steps, per token cost is 6.870\n",
            "After 160 steps, per token cost is 6.916\n",
            "After 170 steps, per token cost is 6.863\n",
            "After 180 steps, per token cost is 6.915\n",
            "After 190 steps, per token cost is 6.815\n",
            "After 200 steps, per token cost is 6.795\n",
            "After 210 steps, per token cost is 6.739\n",
            "After 220 steps, per token cost is 7.017\n",
            "After 230 steps, per token cost is 6.828\n",
            "After 240 steps, per token cost is 6.741\n",
            "After 250 steps, per token cost is 6.771\n",
            "After 260 steps, per token cost is 6.801\n",
            "After 270 steps, per token cost is 6.815\n",
            "After 280 steps, per token cost is 6.785\n",
            "After 290 steps, per token cost is 6.827\n",
            "After 300 steps, per token cost is 6.809\n",
            "After 310 steps, per token cost is 6.760\n",
            "After 320 steps, per token cost is 6.839\n",
            "After 330 steps, per token cost is 7.002\n",
            "After 340 steps, per token cost is 6.819\n",
            "After 350 steps, per token cost is 6.820\n",
            "After 360 steps, per token cost is 6.868\n",
            "After 370 steps, per token cost is 6.621\n",
            "After 380 steps, per token cost is 6.727\n",
            "After 390 steps, per token cost is 6.598\n",
            "-------time cost 198.55794167518616 s\n",
            "                                        \n",
            "-------In iteration: 2\n",
            "After 400 steps, per token cost is 6.839\n",
            "After 410 steps, per token cost is 6.649\n",
            "After 420 steps, per token cost is 6.768\n",
            "After 430 steps, per token cost is 6.824\n",
            "After 440 steps, per token cost is 6.635\n",
            "After 450 steps, per token cost is 6.709\n",
            "After 460 steps, per token cost is 6.610\n",
            "After 470 steps, per token cost is 6.667\n",
            "After 480 steps, per token cost is 6.574\n",
            "After 490 steps, per token cost is 6.725\n",
            "After 500 steps, per token cost is 6.790\n",
            "After 510 steps, per token cost is 6.666\n",
            "After 520 steps, per token cost is 6.698\n",
            "After 530 steps, per token cost is 6.539\n",
            "After 540 steps, per token cost is 6.798\n",
            "After 550 steps, per token cost is 6.583\n",
            "After 560 steps, per token cost is 6.589\n",
            "After 570 steps, per token cost is 6.656\n",
            "After 580 steps, per token cost is 6.602\n",
            "After 590 steps, per token cost is 6.724\n",
            "After 600 steps, per token cost is 6.475\n",
            "After 610 steps, per token cost is 6.579\n",
            "After 620 steps, per token cost is 6.632\n",
            "After 630 steps, per token cost is 6.607\n",
            "After 640 steps, per token cost is 6.339\n",
            "After 650 steps, per token cost is 6.536\n",
            "After 660 steps, per token cost is 6.417\n",
            "After 670 steps, per token cost is 6.430\n",
            "After 680 steps, per token cost is 6.488\n",
            "After 690 steps, per token cost is 6.312\n",
            "After 700 steps, per token cost is 6.182\n",
            "After 710 steps, per token cost is 6.362\n",
            "After 720 steps, per token cost is 6.300\n",
            "After 730 steps, per token cost is 6.337\n",
            "After 740 steps, per token cost is 6.306\n",
            "After 750 steps, per token cost is 6.097\n",
            "After 760 steps, per token cost is 5.949\n",
            "After 770 steps, per token cost is 6.176\n",
            "After 780 steps, per token cost is 6.093\n",
            "-------time cost 195.20275020599365 s\n",
            "                                        \n",
            "-------In iteration: 3\n",
            "After 790 steps, per token cost is 5.998\n",
            "After 800 steps, per token cost is 6.267\n",
            "After 810 steps, per token cost is 6.100\n",
            "After 820 steps, per token cost is 6.217\n",
            "After 830 steps, per token cost is 6.193\n",
            "After 840 steps, per token cost is 6.112\n",
            "After 850 steps, per token cost is 6.108\n",
            "After 860 steps, per token cost is 6.265\n",
            "After 870 steps, per token cost is 5.916\n",
            "After 880 steps, per token cost is 5.995\n",
            "After 890 steps, per token cost is 6.078\n",
            "After 900 steps, per token cost is 5.851\n",
            "After 910 steps, per token cost is 5.997\n",
            "After 920 steps, per token cost is 6.069\n",
            "After 930 steps, per token cost is 6.050\n",
            "After 940 steps, per token cost is 5.892\n",
            "After 950 steps, per token cost is 5.963\n",
            "After 960 steps, per token cost is 6.009\n",
            "After 970 steps, per token cost is 6.064\n",
            "After 980 steps, per token cost is 6.101\n",
            "After 990 steps, per token cost is 6.130\n",
            "After 1000 steps, per token cost is 6.021\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "After 1010 steps, per token cost is 6.128\n",
            "After 1020 steps, per token cost is 6.020\n",
            "After 1030 steps, per token cost is 5.953\n",
            "After 1040 steps, per token cost is 6.022\n",
            "After 1050 steps, per token cost is 5.967\n",
            "After 1060 steps, per token cost is 6.017\n",
            "After 1070 steps, per token cost is 5.996\n",
            "After 1080 steps, per token cost is 5.848\n",
            "After 1090 steps, per token cost is 5.998\n",
            "After 1100 steps, per token cost is 5.920\n",
            "After 1110 steps, per token cost is 5.874\n",
            "After 1120 steps, per token cost is 6.061\n",
            "After 1130 steps, per token cost is 5.923\n",
            "After 1140 steps, per token cost is 5.939\n",
            "After 1150 steps, per token cost is 5.925\n",
            "After 1160 steps, per token cost is 5.815\n",
            "After 1170 steps, per token cost is 5.848\n",
            "-------time cost 193.97336053848267 s\n",
            "                                        \n",
            "-------In iteration: 4\n",
            "After 1180 steps, per token cost is 5.949\n",
            "After 1190 steps, per token cost is 5.910\n",
            "After 1200 steps, per token cost is 5.857\n",
            "After 1210 steps, per token cost is 5.971\n",
            "After 1220 steps, per token cost is 5.892\n",
            "After 1230 steps, per token cost is 5.957\n",
            "After 1240 steps, per token cost is 5.780\n",
            "After 1250 steps, per token cost is 5.741\n",
            "After 1260 steps, per token cost is 5.966\n",
            "After 1270 steps, per token cost is 5.682\n",
            "After 1280 steps, per token cost is 5.819\n",
            "After 1290 steps, per token cost is 5.830\n",
            "After 1300 steps, per token cost is 5.839\n",
            "After 1310 steps, per token cost is 5.843\n",
            "After 1320 steps, per token cost is 5.752\n",
            "After 1330 steps, per token cost is 5.748\n",
            "After 1340 steps, per token cost is 5.678\n",
            "After 1350 steps, per token cost is 5.644\n",
            "After 1360 steps, per token cost is 5.584\n",
            "After 1370 steps, per token cost is 5.811\n",
            "After 1380 steps, per token cost is 5.810\n",
            "After 1390 steps, per token cost is 5.805\n",
            "After 1400 steps, per token cost is 5.917\n",
            "After 1410 steps, per token cost is 5.760\n",
            "After 1420 steps, per token cost is 5.903\n",
            "After 1430 steps, per token cost is 5.928\n",
            "After 1440 steps, per token cost is 5.537\n",
            "After 1450 steps, per token cost is 5.770\n",
            "After 1460 steps, per token cost is 5.896\n",
            "After 1470 steps, per token cost is 5.877\n",
            "After 1480 steps, per token cost is 5.821\n",
            "After 1490 steps, per token cost is 5.790\n",
            "After 1500 steps, per token cost is 5.597\n",
            "After 1510 steps, per token cost is 5.691\n",
            "After 1520 steps, per token cost is 5.824\n",
            "After 1530 steps, per token cost is 5.633\n",
            "After 1540 steps, per token cost is 5.764\n",
            "After 1550 steps, per token cost is 5.673\n",
            "After 1560 steps, per token cost is 5.752\n",
            "-------time cost 194.41723227500916 s\n",
            "                                        \n",
            "-------In iteration: 5\n",
            "After 1570 steps, per token cost is 5.461\n",
            "After 1580 steps, per token cost is 5.628\n",
            "After 1590 steps, per token cost is 5.580\n",
            "After 1600 steps, per token cost is 5.524\n",
            "After 1610 steps, per token cost is 5.501\n",
            "After 1620 steps, per token cost is 5.530\n",
            "After 1630 steps, per token cost is 5.844\n",
            "After 1640 steps, per token cost is 5.468\n",
            "After 1650 steps, per token cost is 5.577\n",
            "After 1660 steps, per token cost is 5.529\n",
            "After 1670 steps, per token cost is 5.452\n",
            "After 1680 steps, per token cost is 5.528\n",
            "After 1690 steps, per token cost is 5.497\n",
            "After 1700 steps, per token cost is 5.495\n",
            "After 1710 steps, per token cost is 5.546\n",
            "After 1720 steps, per token cost is 5.608\n",
            "After 1730 steps, per token cost is 5.424\n",
            "After 1740 steps, per token cost is 5.667\n",
            "After 1750 steps, per token cost is 5.534\n",
            "After 1760 steps, per token cost is 5.451\n",
            "After 1770 steps, per token cost is 5.570\n",
            "After 1780 steps, per token cost is 5.478\n",
            "After 1790 steps, per token cost is 5.418\n",
            "After 1800 steps, per token cost is 5.506\n",
            "After 1810 steps, per token cost is 5.412\n",
            "After 1820 steps, per token cost is 5.708\n",
            "After 1830 steps, per token cost is 5.377\n",
            "After 1840 steps, per token cost is 5.642\n",
            "After 1850 steps, per token cost is 5.686\n",
            "After 1860 steps, per token cost is 5.406\n",
            "After 1870 steps, per token cost is 5.397\n",
            "After 1880 steps, per token cost is 5.671\n",
            "After 1890 steps, per token cost is 5.345\n",
            "After 1900 steps, per token cost is 5.548\n",
            "After 1910 steps, per token cost is 5.533\n",
            "After 1920 steps, per token cost is 5.602\n",
            "After 1930 steps, per token cost is 5.597\n",
            "After 1940 steps, per token cost is 5.468\n",
            "After 1950 steps, per token cost is 5.554\n",
            "-------time cost 193.25144505500793 s\n",
            "                                        \n",
            "-------In iteration: 6\n",
            "After 1960 steps, per token cost is 5.316\n",
            "After 1970 steps, per token cost is 5.514\n",
            "After 1980 steps, per token cost is 5.185\n",
            "After 1990 steps, per token cost is 5.451\n",
            "After 2000 steps, per token cost is 5.542\n",
            "After 2010 steps, per token cost is 5.391\n",
            "After 2020 steps, per token cost is 5.430\n",
            "After 2030 steps, per token cost is 5.564\n",
            "After 2040 steps, per token cost is 5.460\n",
            "After 2050 steps, per token cost is 5.580\n",
            "After 2060 steps, per token cost is 5.389\n",
            "After 2070 steps, per token cost is 5.582\n",
            "After 2080 steps, per token cost is 5.167\n",
            "After 2090 steps, per token cost is 5.255\n",
            "After 2100 steps, per token cost is 5.415\n",
            "After 2110 steps, per token cost is 5.384\n",
            "After 2120 steps, per token cost is 5.537\n",
            "After 2130 steps, per token cost is 5.333\n",
            "After 2140 steps, per token cost is 5.298\n",
            "After 2150 steps, per token cost is 5.450\n",
            "After 2160 steps, per token cost is 5.374\n",
            "After 2170 steps, per token cost is 5.453\n",
            "After 2180 steps, per token cost is 5.416\n",
            "After 2190 steps, per token cost is 5.260\n",
            "After 2200 steps, per token cost is 5.327\n",
            "After 2210 steps, per token cost is 5.571\n",
            "After 2220 steps, per token cost is 5.422\n",
            "After 2230 steps, per token cost is 5.343\n",
            "After 2240 steps, per token cost is 5.220\n",
            "After 2250 steps, per token cost is 5.118\n",
            "After 2260 steps, per token cost is 5.259\n",
            "After 2270 steps, per token cost is 5.201\n",
            "After 2280 steps, per token cost is 5.383\n",
            "After 2290 steps, per token cost is 5.430\n",
            "After 2300 steps, per token cost is 5.380\n",
            "After 2310 steps, per token cost is 5.208\n",
            "After 2320 steps, per token cost is 5.424\n",
            "After 2330 steps, per token cost is 5.449\n",
            "After 2340 steps, per token cost is 5.362\n",
            "-------time cost 192.77915811538696 s\n",
            "                                        \n",
            "-------In iteration: 7\n",
            "After 2350 steps, per token cost is 5.218\n",
            "After 2360 steps, per token cost is 5.313\n",
            "After 2370 steps, per token cost is 5.237\n",
            "After 2380 steps, per token cost is 5.359\n",
            "After 2390 steps, per token cost is 5.310\n",
            "After 2400 steps, per token cost is 5.494\n",
            "After 2410 steps, per token cost is 5.396\n",
            "After 2420 steps, per token cost is 5.181\n",
            "After 2430 steps, per token cost is 5.248\n",
            "After 2440 steps, per token cost is 5.388\n",
            "After 2450 steps, per token cost is 5.252\n",
            "After 2460 steps, per token cost is 5.263\n",
            "After 2470 steps, per token cost is 4.975\n",
            "After 2480 steps, per token cost is 5.203\n",
            "After 2490 steps, per token cost is 5.119\n",
            "After 2500 steps, per token cost is 5.233\n",
            "After 2510 steps, per token cost is 5.267\n",
            "After 2520 steps, per token cost is 5.394\n",
            "After 2530 steps, per token cost is 5.192\n",
            "After 2540 steps, per token cost is 5.286\n",
            "After 2550 steps, per token cost is 5.019\n",
            "After 2560 steps, per token cost is 5.232\n",
            "After 2570 steps, per token cost is 5.360\n",
            "After 2580 steps, per token cost is 5.311\n",
            "After 2590 steps, per token cost is 5.035\n",
            "After 2600 steps, per token cost is 5.284\n",
            "After 2610 steps, per token cost is 5.243\n",
            "After 2620 steps, per token cost is 5.032\n",
            "After 2630 steps, per token cost is 5.541\n",
            "After 2640 steps, per token cost is 5.072\n",
            "After 2650 steps, per token cost is 5.229\n",
            "After 2660 steps, per token cost is 5.281\n",
            "After 2670 steps, per token cost is 5.190\n",
            "After 2680 steps, per token cost is 5.122\n",
            "After 2690 steps, per token cost is 5.170\n",
            "After 2700 steps, per token cost is 5.546\n",
            "After 2710 steps, per token cost is 5.051\n",
            "After 2720 steps, per token cost is 5.407\n",
            "After 2730 steps, per token cost is 5.141\n",
            "-------time cost 193.10875296592712 s\n",
            "                                        \n",
            "-------In iteration: 8\n",
            "After 2740 steps, per token cost is 5.085\n",
            "After 2750 steps, per token cost is 5.018\n",
            "After 2760 steps, per token cost is 5.064\n",
            "After 2770 steps, per token cost is 4.999\n",
            "After 2780 steps, per token cost is 5.091\n",
            "After 2790 steps, per token cost is 5.245\n",
            "After 2800 steps, per token cost is 5.310\n",
            "After 2810 steps, per token cost is 5.166\n",
            "After 2820 steps, per token cost is 5.237\n",
            "After 2830 steps, per token cost is 5.214\n",
            "After 2840 steps, per token cost is 5.203\n",
            "After 2850 steps, per token cost is 5.061\n",
            "After 2860 steps, per token cost is 5.218\n",
            "After 2870 steps, per token cost is 5.188\n",
            "After 2880 steps, per token cost is 5.138\n",
            "After 2890 steps, per token cost is 5.228\n",
            "After 2900 steps, per token cost is 5.163\n",
            "After 2910 steps, per token cost is 5.039\n",
            "After 2920 steps, per token cost is 5.119\n",
            "After 2930 steps, per token cost is 5.130\n",
            "After 2940 steps, per token cost is 5.000\n",
            "After 2950 steps, per token cost is 5.127\n",
            "After 2960 steps, per token cost is 5.187\n",
            "After 2970 steps, per token cost is 5.185\n",
            "After 2980 steps, per token cost is 5.055\n",
            "After 2990 steps, per token cost is 4.945\n",
            "After 3000 steps, per token cost is 5.015\n",
            "After 3010 steps, per token cost is 5.107\n",
            "After 3020 steps, per token cost is 5.197\n",
            "After 3030 steps, per token cost is 5.062\n",
            "After 3040 steps, per token cost is 5.018\n",
            "After 3050 steps, per token cost is 5.048\n",
            "After 3060 steps, per token cost is 4.868\n",
            "After 3070 steps, per token cost is 5.213\n",
            "After 3080 steps, per token cost is 4.957\n",
            "After 3090 steps, per token cost is 5.030\n",
            "After 3100 steps, per token cost is 5.310\n",
            "After 3110 steps, per token cost is 5.069\n",
            "After 3120 steps, per token cost is 5.144\n",
            "-------time cost 193.30431532859802 s\n",
            "                                        \n",
            "-------In iteration: 9\n",
            "After 3130 steps, per token cost is 5.172\n",
            "After 3140 steps, per token cost is 5.119\n",
            "After 3150 steps, per token cost is 4.769\n",
            "After 3160 steps, per token cost is 5.191\n",
            "After 3170 steps, per token cost is 5.078\n",
            "After 3180 steps, per token cost is 4.840\n",
            "After 3190 steps, per token cost is 5.013\n",
            "After 3200 steps, per token cost is 4.790\n",
            "After 3210 steps, per token cost is 4.988\n",
            "After 3220 steps, per token cost is 4.992\n",
            "After 3230 steps, per token cost is 4.855\n",
            "After 3240 steps, per token cost is 4.943\n",
            "After 3250 steps, per token cost is 5.103\n",
            "After 3260 steps, per token cost is 5.036\n",
            "After 3270 steps, per token cost is 5.031\n",
            "After 3280 steps, per token cost is 4.939\n",
            "After 3290 steps, per token cost is 5.041\n",
            "After 3300 steps, per token cost is 5.000\n",
            "After 3310 steps, per token cost is 4.713\n",
            "After 3320 steps, per token cost is 4.946\n",
            "After 3330 steps, per token cost is 5.078\n",
            "After 3340 steps, per token cost is 5.134\n",
            "After 3350 steps, per token cost is 5.126\n",
            "After 3360 steps, per token cost is 5.222\n",
            "After 3370 steps, per token cost is 4.972\n",
            "After 3380 steps, per token cost is 4.703\n",
            "After 3390 steps, per token cost is 4.835\n",
            "After 3400 steps, per token cost is 4.997\n",
            "After 3410 steps, per token cost is 5.036\n",
            "After 3420 steps, per token cost is 4.716\n",
            "After 3430 steps, per token cost is 4.815\n",
            "After 3440 steps, per token cost is 4.941\n",
            "After 3450 steps, per token cost is 4.959\n",
            "After 3460 steps, per token cost is 5.124\n",
            "After 3470 steps, per token cost is 4.911\n",
            "After 3480 steps, per token cost is 4.966\n",
            "After 3490 steps, per token cost is 5.022\n",
            "After 3500 steps, per token cost is 4.835\n",
            "After 3510 steps, per token cost is 4.931\n",
            "-------time cost 194.97608160972595 s\n",
            "                                        \n",
            "-------In iteration: 10\n",
            "After 3520 steps, per token cost is 5.111\n",
            "After 3530 steps, per token cost is 5.024\n",
            "After 3540 steps, per token cost is 4.865\n",
            "After 3550 steps, per token cost is 4.806\n",
            "After 3560 steps, per token cost is 4.890\n",
            "After 3570 steps, per token cost is 4.958\n",
            "After 3580 steps, per token cost is 4.739\n",
            "After 3590 steps, per token cost is 4.943\n",
            "After 3600 steps, per token cost is 4.881\n",
            "After 3610 steps, per token cost is 4.894\n",
            "After 3620 steps, per token cost is 4.734\n",
            "After 3630 steps, per token cost is 4.800\n",
            "After 3640 steps, per token cost is 4.820\n",
            "After 3650 steps, per token cost is 4.959\n",
            "After 3660 steps, per token cost is 4.900\n",
            "After 3670 steps, per token cost is 4.924\n",
            "After 3680 steps, per token cost is 5.143\n",
            "After 3690 steps, per token cost is 4.901\n",
            "After 3700 steps, per token cost is 4.867\n",
            "After 3710 steps, per token cost is 4.990\n",
            "After 3720 steps, per token cost is 4.936\n",
            "After 3730 steps, per token cost is 4.753\n",
            "After 3740 steps, per token cost is 4.960\n",
            "After 3750 steps, per token cost is 4.848\n",
            "After 3760 steps, per token cost is 4.942\n",
            "After 3770 steps, per token cost is 4.929\n",
            "After 3780 steps, per token cost is 4.875\n",
            "After 3790 steps, per token cost is 4.957\n",
            "After 3800 steps, per token cost is 5.033\n",
            "After 3810 steps, per token cost is 4.769\n",
            "After 3820 steps, per token cost is 4.899\n",
            "After 3830 steps, per token cost is 5.044\n",
            "After 3840 steps, per token cost is 4.812\n",
            "After 3850 steps, per token cost is 4.964\n",
            "After 3860 steps, per token cost is 4.645\n",
            "After 3870 steps, per token cost is 4.617\n",
            "After 3880 steps, per token cost is 4.785\n",
            "After 3890 steps, per token cost is 4.773\n",
            "After 3900 steps, per token cost is 4.876\n",
            "-------time cost 192.90391564369202 s\n",
            "                                        \n",
            "-------In iteration: 11\n",
            "After 3910 steps, per token cost is 4.842\n",
            "After 3920 steps, per token cost is 5.034\n",
            "After 3930 steps, per token cost is 4.900\n",
            "After 3940 steps, per token cost is 4.800\n",
            "After 3950 steps, per token cost is 4.797\n",
            "After 3960 steps, per token cost is 4.841\n",
            "After 3970 steps, per token cost is 4.849\n",
            "After 3980 steps, per token cost is 4.732\n",
            "After 3990 steps, per token cost is 4.608\n",
            "After 4000 steps, per token cost is 4.701\n",
            "After 4010 steps, per token cost is 4.643\n",
            "After 4020 steps, per token cost is 4.835\n",
            "After 4030 steps, per token cost is 5.013\n",
            "After 4040 steps, per token cost is 4.577\n",
            "After 4050 steps, per token cost is 4.939\n",
            "After 4060 steps, per token cost is 4.788\n",
            "After 4070 steps, per token cost is 4.991\n",
            "After 4080 steps, per token cost is 4.992\n",
            "After 4090 steps, per token cost is 4.736\n",
            "After 4100 steps, per token cost is 4.824\n",
            "After 4110 steps, per token cost is 4.695\n",
            "After 4120 steps, per token cost is 4.860\n",
            "After 4130 steps, per token cost is 4.926\n",
            "After 4140 steps, per token cost is 4.657\n",
            "After 4150 steps, per token cost is 4.700\n",
            "After 4160 steps, per token cost is 4.704\n",
            "After 4170 steps, per token cost is 4.864\n",
            "After 4180 steps, per token cost is 4.677\n",
            "After 4190 steps, per token cost is 4.800\n",
            "After 4200 steps, per token cost is 4.741\n",
            "After 4210 steps, per token cost is 4.751\n",
            "After 4220 steps, per token cost is 4.473\n",
            "After 4230 steps, per token cost is 4.884\n",
            "After 4240 steps, per token cost is 4.856\n",
            "After 4250 steps, per token cost is 4.705\n",
            "After 4260 steps, per token cost is 4.902\n",
            "After 4270 steps, per token cost is 4.646\n",
            "After 4280 steps, per token cost is 4.859\n",
            "After 4290 steps, per token cost is 4.679\n",
            "After 4300 steps, per token cost is 4.541\n",
            "-------time cost 193.15551829338074 s\n",
            "                                        \n",
            "-------In iteration: 12\n",
            "After 4310 steps, per token cost is 4.615\n",
            "After 4320 steps, per token cost is 4.702\n",
            "After 4330 steps, per token cost is 4.604\n",
            "After 4340 steps, per token cost is 4.749\n",
            "After 4350 steps, per token cost is 4.535\n",
            "After 4360 steps, per token cost is 4.615\n",
            "After 4370 steps, per token cost is 4.666\n",
            "After 4380 steps, per token cost is 4.901\n",
            "After 4390 steps, per token cost is 4.577\n",
            "After 4400 steps, per token cost is 4.706\n",
            "After 4410 steps, per token cost is 4.812\n",
            "After 4420 steps, per token cost is 4.407\n",
            "After 4430 steps, per token cost is 4.808\n",
            "After 4440 steps, per token cost is 4.557\n",
            "After 4450 steps, per token cost is 4.639\n",
            "After 4460 steps, per token cost is 4.798\n",
            "After 4470 steps, per token cost is 4.618\n",
            "After 4480 steps, per token cost is 4.677\n",
            "After 4490 steps, per token cost is 4.764\n",
            "After 4500 steps, per token cost is 4.635\n",
            "After 4510 steps, per token cost is 4.884\n",
            "After 4520 steps, per token cost is 4.487\n",
            "After 4530 steps, per token cost is 4.713\n",
            "After 4540 steps, per token cost is 4.611\n",
            "After 4550 steps, per token cost is 4.666\n",
            "After 4560 steps, per token cost is 4.687\n",
            "After 4570 steps, per token cost is 4.716\n",
            "After 4580 steps, per token cost is 4.539\n",
            "After 4590 steps, per token cost is 4.972\n",
            "After 4600 steps, per token cost is 4.690\n",
            "After 4610 steps, per token cost is 4.729\n",
            "After 4620 steps, per token cost is 4.515\n",
            "After 4630 steps, per token cost is 4.805\n",
            "After 4640 steps, per token cost is 4.801\n",
            "After 4650 steps, per token cost is 4.535\n",
            "After 4660 steps, per token cost is 4.814\n",
            "After 4670 steps, per token cost is 4.746\n",
            "After 4680 steps, per token cost is 4.368\n",
            "After 4690 steps, per token cost is 4.787\n",
            "-------time cost 193.36864495277405 s\n",
            "                                        \n",
            "-------In iteration: 13\n",
            "After 4700 steps, per token cost is 4.603\n",
            "After 4710 steps, per token cost is 4.715\n",
            "After 4720 steps, per token cost is 4.652\n",
            "After 4730 steps, per token cost is 4.572\n",
            "After 4740 steps, per token cost is 4.369\n",
            "After 4750 steps, per token cost is 4.481\n",
            "After 4760 steps, per token cost is 4.540\n",
            "After 4770 steps, per token cost is 4.605\n",
            "After 4780 steps, per token cost is 4.479\n",
            "After 4790 steps, per token cost is 4.856\n",
            "After 4800 steps, per token cost is 4.802\n",
            "After 4810 steps, per token cost is 4.551\n",
            "After 4820 steps, per token cost is 4.732\n",
            "After 4830 steps, per token cost is 4.558\n",
            "After 4840 steps, per token cost is 4.735\n",
            "After 4850 steps, per token cost is 4.687\n",
            "After 4860 steps, per token cost is 4.556\n",
            "After 4870 steps, per token cost is 4.709\n",
            "After 4880 steps, per token cost is 4.664\n",
            "After 4890 steps, per token cost is 4.584\n",
            "After 4900 steps, per token cost is 4.572\n",
            "After 4910 steps, per token cost is 4.838\n",
            "After 4920 steps, per token cost is 4.505\n",
            "After 4930 steps, per token cost is 4.589\n",
            "After 4940 steps, per token cost is 4.694\n",
            "After 4950 steps, per token cost is 4.651\n",
            "After 4960 steps, per token cost is 4.442\n",
            "After 4970 steps, per token cost is 4.550\n",
            "After 4980 steps, per token cost is 4.540\n",
            "After 4990 steps, per token cost is 4.643\n",
            "After 5000 steps, per token cost is 4.606\n",
            "After 5010 steps, per token cost is 4.594\n",
            "After 5020 steps, per token cost is 4.750\n",
            "After 5030 steps, per token cost is 4.613\n",
            "After 5040 steps, per token cost is 4.583\n",
            "After 5050 steps, per token cost is 4.601\n",
            "After 5060 steps, per token cost is 4.696\n",
            "After 5070 steps, per token cost is 4.736\n",
            "After 5080 steps, per token cost is 4.630\n",
            "-------time cost 193.12156319618225 s\n",
            "                                        \n",
            "-------In iteration: 14\n",
            "After 5090 steps, per token cost is 4.571\n",
            "After 5100 steps, per token cost is 4.487\n",
            "After 5110 steps, per token cost is 4.606\n",
            "After 5120 steps, per token cost is 4.519\n",
            "After 5130 steps, per token cost is 4.440\n",
            "After 5140 steps, per token cost is 4.511\n",
            "After 5150 steps, per token cost is 4.447\n",
            "After 5160 steps, per token cost is 4.547\n",
            "After 5170 steps, per token cost is 4.448\n",
            "After 5180 steps, per token cost is 4.565\n",
            "After 5190 steps, per token cost is 4.638\n",
            "After 5200 steps, per token cost is 4.388\n",
            "After 5210 steps, per token cost is 4.561\n",
            "After 5220 steps, per token cost is 4.744\n",
            "After 5230 steps, per token cost is 4.645\n",
            "After 5240 steps, per token cost is 4.628\n",
            "After 5250 steps, per token cost is 4.732\n",
            "After 5260 steps, per token cost is 4.637\n",
            "After 5270 steps, per token cost is 4.436\n",
            "After 5280 steps, per token cost is 4.636\n",
            "After 5290 steps, per token cost is 4.615\n",
            "After 5300 steps, per token cost is 4.594\n",
            "After 5310 steps, per token cost is 4.550\n",
            "After 5320 steps, per token cost is 4.583\n",
            "After 5330 steps, per token cost is 4.758\n",
            "After 5340 steps, per token cost is 4.466\n",
            "After 5350 steps, per token cost is 4.445\n",
            "After 5360 steps, per token cost is 4.543\n",
            "After 5370 steps, per token cost is 4.319\n",
            "After 5380 steps, per token cost is 4.662\n",
            "After 5390 steps, per token cost is 4.539\n",
            "After 5400 steps, per token cost is 4.358\n",
            "After 5410 steps, per token cost is 4.666\n",
            "After 5420 steps, per token cost is 4.556\n",
            "After 5430 steps, per token cost is 4.535\n",
            "After 5440 steps, per token cost is 4.468\n",
            "After 5450 steps, per token cost is 4.397\n",
            "After 5460 steps, per token cost is 4.756\n",
            "After 5470 steps, per token cost is 4.617\n",
            "-------time cost 192.57023406028748 s\n",
            "                                        \n",
            "-------In iteration: 15\n",
            "After 5480 steps, per token cost is 4.566\n",
            "After 5490 steps, per token cost is 4.653\n",
            "After 5500 steps, per token cost is 4.575\n",
            "After 5510 steps, per token cost is 4.515\n",
            "After 5520 steps, per token cost is 4.518\n",
            "After 5530 steps, per token cost is 4.511\n",
            "After 5540 steps, per token cost is 4.559\n",
            "After 5550 steps, per token cost is 4.440\n",
            "After 5560 steps, per token cost is 4.402\n",
            "After 5570 steps, per token cost is 4.551\n",
            "After 5580 steps, per token cost is 4.449\n",
            "After 5590 steps, per token cost is 4.446\n",
            "After 5600 steps, per token cost is 4.671\n",
            "After 5610 steps, per token cost is 4.518\n",
            "After 5620 steps, per token cost is 4.358\n",
            "After 5630 steps, per token cost is 4.621\n",
            "After 5640 steps, per token cost is 4.495\n",
            "After 5650 steps, per token cost is 4.390\n",
            "After 5660 steps, per token cost is 4.496\n",
            "After 5670 steps, per token cost is 4.628\n",
            "After 5680 steps, per token cost is 4.332\n",
            "After 5690 steps, per token cost is 4.380\n",
            "After 5700 steps, per token cost is 4.578\n",
            "After 5710 steps, per token cost is 4.623\n",
            "After 5720 steps, per token cost is 4.510\n",
            "After 5730 steps, per token cost is 4.676\n",
            "After 5740 steps, per token cost is 4.632\n",
            "After 5750 steps, per token cost is 4.620\n",
            "After 5760 steps, per token cost is 4.467\n",
            "After 5770 steps, per token cost is 4.459\n",
            "After 5780 steps, per token cost is 4.732\n",
            "After 5790 steps, per token cost is 4.532\n",
            "After 5800 steps, per token cost is 4.321\n",
            "After 5810 steps, per token cost is 4.606\n",
            "After 5820 steps, per token cost is 4.224\n",
            "After 5830 steps, per token cost is 4.477\n",
            "After 5840 steps, per token cost is 4.614\n",
            "After 5850 steps, per token cost is 4.450\n",
            "After 5860 steps, per token cost is 4.590\n",
            "-------time cost 193.2758378982544 s\n",
            "                                        \n",
            "-------In iteration: 16\n",
            "After 5870 steps, per token cost is 4.653\n",
            "After 5880 steps, per token cost is 4.484\n",
            "After 5890 steps, per token cost is 4.272\n",
            "After 5900 steps, per token cost is 4.589\n",
            "After 5910 steps, per token cost is 4.427\n",
            "After 5920 steps, per token cost is 4.442\n",
            "After 5930 steps, per token cost is 4.461\n",
            "After 5940 steps, per token cost is 4.400\n",
            "After 5950 steps, per token cost is 4.475\n",
            "After 5960 steps, per token cost is 4.300\n",
            "After 5970 steps, per token cost is 4.532\n",
            "After 5980 steps, per token cost is 4.523\n",
            "After 5990 steps, per token cost is 4.437\n",
            "After 6000 steps, per token cost is 4.536\n",
            "After 6010 steps, per token cost is 4.512\n",
            "After 6020 steps, per token cost is 4.363\n",
            "After 6030 steps, per token cost is 4.399\n",
            "After 6040 steps, per token cost is 4.379\n",
            "After 6050 steps, per token cost is 4.657\n",
            "After 6060 steps, per token cost is 4.318\n",
            "After 6070 steps, per token cost is 4.509\n",
            "After 6080 steps, per token cost is 4.382\n",
            "After 6090 steps, per token cost is 4.489\n",
            "After 6100 steps, per token cost is 4.482\n",
            "After 6110 steps, per token cost is 4.308\n",
            "After 6120 steps, per token cost is 4.382\n",
            "After 6130 steps, per token cost is 4.481\n",
            "After 6140 steps, per token cost is 4.371\n",
            "After 6150 steps, per token cost is 4.303\n",
            "After 6160 steps, per token cost is 4.241\n",
            "After 6170 steps, per token cost is 4.545\n",
            "After 6180 steps, per token cost is 4.589\n",
            "After 6190 steps, per token cost is 4.498\n",
            "After 6200 steps, per token cost is 4.584\n",
            "After 6210 steps, per token cost is 4.557\n",
            "After 6220 steps, per token cost is 4.689\n",
            "After 6230 steps, per token cost is 4.342\n",
            "After 6240 steps, per token cost is 4.520\n",
            "After 6250 steps, per token cost is 4.493\n",
            "-------time cost 190.16644406318665 s\n",
            "                                        \n",
            "-------In iteration: 17\n",
            "After 6260 steps, per token cost is 4.534\n",
            "After 6270 steps, per token cost is 4.507\n",
            "After 6280 steps, per token cost is 4.494\n",
            "After 6290 steps, per token cost is 4.343\n",
            "After 6300 steps, per token cost is 4.266\n",
            "After 6310 steps, per token cost is 4.430\n",
            "After 6320 steps, per token cost is 4.238\n",
            "After 6330 steps, per token cost is 4.443\n",
            "After 6340 steps, per token cost is 4.399\n",
            "After 6350 steps, per token cost is 4.405\n",
            "After 6360 steps, per token cost is 4.661\n",
            "After 6370 steps, per token cost is 4.245\n",
            "After 6380 steps, per token cost is 4.408\n",
            "After 6390 steps, per token cost is 4.412\n",
            "After 6400 steps, per token cost is 4.545\n",
            "After 6410 steps, per token cost is 4.269\n",
            "After 6420 steps, per token cost is 4.480\n",
            "After 6430 steps, per token cost is 4.486\n",
            "After 6440 steps, per token cost is 4.448\n",
            "After 6450 steps, per token cost is 4.261\n",
            "After 6460 steps, per token cost is 4.385\n",
            "After 6470 steps, per token cost is 4.573\n",
            "After 6480 steps, per token cost is 4.622\n",
            "After 6490 steps, per token cost is 4.591\n",
            "After 6500 steps, per token cost is 4.388\n",
            "After 6510 steps, per token cost is 4.206\n",
            "After 6520 steps, per token cost is 4.433\n",
            "After 6530 steps, per token cost is 4.426\n",
            "After 6540 steps, per token cost is 4.239\n",
            "After 6550 steps, per token cost is 4.403\n",
            "After 6560 steps, per token cost is 4.495\n",
            "After 6570 steps, per token cost is 4.449\n",
            "After 6580 steps, per token cost is 4.103\n",
            "After 6590 steps, per token cost is 4.323\n",
            "After 6600 steps, per token cost is 4.533\n",
            "After 6610 steps, per token cost is 4.607\n",
            "After 6620 steps, per token cost is 4.795\n",
            "After 6630 steps, per token cost is 4.270\n",
            "After 6640 steps, per token cost is 4.151\n",
            "-------time cost 190.07732248306274 s\n",
            "                                        \n",
            "-------In iteration: 18\n",
            "After 6650 steps, per token cost is 4.369\n",
            "After 6660 steps, per token cost is 4.223\n",
            "After 6670 steps, per token cost is 4.313\n",
            "After 6680 steps, per token cost is 4.213\n",
            "After 6690 steps, per token cost is 4.153\n",
            "After 6700 steps, per token cost is 4.506\n",
            "After 6710 steps, per token cost is 4.426\n",
            "After 6720 steps, per token cost is 4.401\n",
            "After 6730 steps, per token cost is 4.108\n",
            "After 6740 steps, per token cost is 4.279\n",
            "After 6750 steps, per token cost is 4.307\n",
            "After 6760 steps, per token cost is 4.211\n",
            "After 6770 steps, per token cost is 4.138\n",
            "After 6780 steps, per token cost is 4.207\n",
            "After 6790 steps, per token cost is 4.279\n",
            "After 6800 steps, per token cost is 4.379\n",
            "After 6810 steps, per token cost is 4.505\n",
            "After 6820 steps, per token cost is 4.498\n",
            "After 6830 steps, per token cost is 4.584\n",
            "After 6840 steps, per token cost is 4.288\n",
            "After 6850 steps, per token cost is 4.509\n",
            "After 6860 steps, per token cost is 4.430\n",
            "After 6870 steps, per token cost is 4.255\n",
            "After 6880 steps, per token cost is 4.487\n",
            "After 6890 steps, per token cost is 4.345\n",
            "After 6900 steps, per token cost is 4.245\n",
            "After 6910 steps, per token cost is 4.227\n",
            "After 6920 steps, per token cost is 4.289\n",
            "After 6930 steps, per token cost is 4.550\n",
            "After 6940 steps, per token cost is 4.504\n",
            "After 6950 steps, per token cost is 4.303\n",
            "After 6960 steps, per token cost is 4.234\n",
            "After 6970 steps, per token cost is 4.165\n",
            "After 6980 steps, per token cost is 4.365\n",
            "After 6990 steps, per token cost is 4.193\n",
            "After 7000 steps, per token cost is 4.168\n",
            "After 7010 steps, per token cost is 4.437\n",
            "After 7020 steps, per token cost is 4.580\n",
            "After 7030 steps, per token cost is 4.396\n",
            "-------time cost 189.70219039916992 s\n",
            "                                        \n",
            "-------In iteration: 19\n",
            "After 7040 steps, per token cost is 4.331\n",
            "After 7050 steps, per token cost is 4.345\n",
            "After 7060 steps, per token cost is 4.266\n",
            "After 7070 steps, per token cost is 4.255\n",
            "After 7080 steps, per token cost is 4.166\n",
            "After 7090 steps, per token cost is 4.322\n",
            "After 7100 steps, per token cost is 4.261\n",
            "After 7110 steps, per token cost is 4.273\n",
            "After 7120 steps, per token cost is 4.447\n",
            "After 7130 steps, per token cost is 4.336\n",
            "After 7140 steps, per token cost is 4.129\n",
            "After 7150 steps, per token cost is 4.335\n",
            "After 7160 steps, per token cost is 4.265\n",
            "After 7170 steps, per token cost is 4.178\n",
            "After 7180 steps, per token cost is 4.208\n",
            "After 7190 steps, per token cost is 4.136\n",
            "After 7200 steps, per token cost is 4.366\n",
            "After 7210 steps, per token cost is 4.185\n",
            "After 7220 steps, per token cost is 4.555\n",
            "After 7230 steps, per token cost is 4.316\n",
            "After 7240 steps, per token cost is 4.136\n",
            "After 7250 steps, per token cost is 4.309\n",
            "After 7260 steps, per token cost is 4.369\n",
            "After 7270 steps, per token cost is 4.233\n",
            "After 7280 steps, per token cost is 4.355\n",
            "After 7290 steps, per token cost is 4.034\n",
            "After 7300 steps, per token cost is 4.387\n",
            "After 7310 steps, per token cost is 4.306\n",
            "After 7320 steps, per token cost is 4.136\n",
            "After 7330 steps, per token cost is 4.133\n",
            "After 7340 steps, per token cost is 4.330\n",
            "After 7350 steps, per token cost is 4.132\n",
            "After 7360 steps, per token cost is 4.156\n",
            "After 7370 steps, per token cost is 4.124\n",
            "After 7380 steps, per token cost is 4.407\n",
            "After 7390 steps, per token cost is 4.130\n",
            "After 7400 steps, per token cost is 4.362\n",
            "After 7410 steps, per token cost is 4.299\n",
            "After 7420 steps, per token cost is 4.257\n",
            "-------time cost 191.02138996124268 s\n",
            "                                        \n",
            "-------In iteration: 20\n",
            "After 7430 steps, per token cost is 4.018\n",
            "After 7440 steps, per token cost is 4.165\n",
            "After 7450 steps, per token cost is 4.572\n",
            "After 7460 steps, per token cost is 4.263\n",
            "After 7470 steps, per token cost is 4.116\n",
            "After 7480 steps, per token cost is 4.016\n",
            "After 7490 steps, per token cost is 4.279\n",
            "After 7500 steps, per token cost is 4.001\n",
            "After 7510 steps, per token cost is 4.102\n",
            "After 7520 steps, per token cost is 4.213\n",
            "After 7530 steps, per token cost is 4.267\n",
            "After 7540 steps, per token cost is 4.021\n",
            "After 7550 steps, per token cost is 4.367\n",
            "After 7560 steps, per token cost is 3.858\n",
            "After 7570 steps, per token cost is 4.211\n",
            "After 7580 steps, per token cost is 4.303\n",
            "After 7590 steps, per token cost is 4.250\n",
            "After 7600 steps, per token cost is 4.228\n",
            "After 7610 steps, per token cost is 4.228\n",
            "After 7620 steps, per token cost is 4.116\n",
            "After 7630 steps, per token cost is 4.295\n",
            "After 7640 steps, per token cost is 4.317\n",
            "After 7650 steps, per token cost is 4.158\n",
            "After 7660 steps, per token cost is 4.220\n",
            "After 7670 steps, per token cost is 4.170\n",
            "After 7680 steps, per token cost is 4.252\n",
            "After 7690 steps, per token cost is 4.255\n",
            "After 7700 steps, per token cost is 4.104\n",
            "After 7710 steps, per token cost is 4.119\n",
            "After 7720 steps, per token cost is 4.135\n",
            "After 7730 steps, per token cost is 4.042\n",
            "After 7740 steps, per token cost is 4.327\n",
            "After 7750 steps, per token cost is 4.184\n",
            "After 7760 steps, per token cost is 4.399\n",
            "After 7770 steps, per token cost is 4.243\n",
            "After 7780 steps, per token cost is 4.508\n",
            "After 7790 steps, per token cost is 4.470\n",
            "After 7800 steps, per token cost is 4.434\n",
            "After 7810 steps, per token cost is 4.226\n",
            "-------time cost 190.31876063346863 s\n",
            "                                        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1Yziyjq3uThj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5. Produce Model Structure"
      ]
    },
    {
      "metadata": {
        "id": "FeXy_r_TphJL",
        "colab_type": "code",
        "outputId": "1c003aea-c0e0-405f-ba2c-0fcf4f7ff53a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow.contrib.slim as slim\n",
        "\n",
        "def model_summary():\n",
        "    model_vars = tf.trainable_variables()\n",
        "    slim.model_analyzer.analyze_vars(model_vars, print_info=True)\n",
        "\n",
        "model_summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------\n",
            "Variables: name (type shape) [size]\n",
            "---------\n",
            "nmt_model/src_emb:0 (float32_ref 28711x128) [3675008, bytes: 14700032]\n",
            "nmt_model/trg_emb:0 (float32_ref 35019x128) [4482432, bytes: 17929728]\n",
            "nmt_model/softmax_bias:0 (float32_ref 35019) [35019, bytes: 140076]\n",
            "encoder/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/kernel:0 (float32 256x512) [131072, bytes: 524288]\n",
            "encoder/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/bias:0 (float32 512) [512, bytes: 2048]\n",
            "encoder/bidirectional_rnn/fw/multi_rnn_cell/cell_1/lstm_cell/kernel:0 (float32 256x512) [131072, bytes: 524288]\n",
            "encoder/bidirectional_rnn/fw/multi_rnn_cell/cell_1/lstm_cell/bias:0 (float32 512) [512, bytes: 2048]\n",
            "encoder/bidirectional_rnn/fw/multi_rnn_cell/cell_2/lstm_cell/kernel:0 (float32 256x512) [131072, bytes: 524288]\n",
            "encoder/bidirectional_rnn/fw/multi_rnn_cell/cell_2/lstm_cell/bias:0 (float32 512) [512, bytes: 2048]\n",
            "encoder/bidirectional_rnn/fw/multi_rnn_cell/cell_3/lstm_cell/kernel:0 (float32 256x512) [131072, bytes: 524288]\n",
            "encoder/bidirectional_rnn/fw/multi_rnn_cell/cell_3/lstm_cell/bias:0 (float32 512) [512, bytes: 2048]\n",
            "encoder/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/kernel:0 (float32 256x512) [131072, bytes: 524288]\n",
            "encoder/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/bias:0 (float32 512) [512, bytes: 2048]\n",
            "encoder/bidirectional_rnn/bw/multi_rnn_cell/cell_1/lstm_cell/kernel:0 (float32 256x512) [131072, bytes: 524288]\n",
            "encoder/bidirectional_rnn/bw/multi_rnn_cell/cell_1/lstm_cell/bias:0 (float32 512) [512, bytes: 2048]\n",
            "encoder/bidirectional_rnn/bw/multi_rnn_cell/cell_2/lstm_cell/kernel:0 (float32 256x512) [131072, bytes: 524288]\n",
            "encoder/bidirectional_rnn/bw/multi_rnn_cell/cell_2/lstm_cell/bias:0 (float32 512) [512, bytes: 2048]\n",
            "encoder/bidirectional_rnn/bw/multi_rnn_cell/cell_3/lstm_cell/kernel:0 (float32 256x512) [131072, bytes: 524288]\n",
            "encoder/bidirectional_rnn/bw/multi_rnn_cell/cell_3/lstm_cell/bias:0 (float32 512) [512, bytes: 2048]\n",
            "decoder/memory_layer/kernel:0 (float32_ref 256x128) [32768, bytes: 131072]\n",
            "decoder/rnn/attention_wrapper/multi_rnn_cell/cell_0/lstm_cell/kernel:0 (float32 384x512) [196608, bytes: 786432]\n",
            "decoder/rnn/attention_wrapper/multi_rnn_cell/cell_0/lstm_cell/bias:0 (float32 512) [512, bytes: 2048]\n",
            "decoder/rnn/attention_wrapper/multi_rnn_cell/cell_1/lstm_cell/kernel:0 (float32 256x512) [131072, bytes: 524288]\n",
            "decoder/rnn/attention_wrapper/multi_rnn_cell/cell_1/lstm_cell/bias:0 (float32 512) [512, bytes: 2048]\n",
            "decoder/rnn/attention_wrapper/multi_rnn_cell/cell_2/lstm_cell/kernel:0 (float32 256x512) [131072, bytes: 524288]\n",
            "decoder/rnn/attention_wrapper/multi_rnn_cell/cell_2/lstm_cell/bias:0 (float32 512) [512, bytes: 2048]\n",
            "decoder/rnn/attention_wrapper/multi_rnn_cell/cell_3/lstm_cell/kernel:0 (float32 256x512) [131072, bytes: 524288]\n",
            "decoder/rnn/attention_wrapper/multi_rnn_cell/cell_3/lstm_cell/bias:0 (float32 512) [512, bytes: 2048]\n",
            "decoder/rnn/attention_wrapper/bahdanau_attention/query_layer/kernel:0 (float32_ref 128x128) [16384, bytes: 65536]\n",
            "decoder/rnn/attention_wrapper/bahdanau_attention/attention_v:0 (float32_ref 128) [128, bytes: 512]\n",
            "decoder/rnn/attention_wrapper/attention_layer/kernel:0 (float32_ref 384x128) [49152, bytes: 196608]\n",
            "Total size of variables: 9935435\n",
            "Total bytes of variables: 39741740\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZacotbTLTRbj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# INSTRUCTION 3 - INFERENCE USING TRAINED MODEL AND WEIGHT"
      ]
    },
    {
      "metadata": {
        "id": "xci8p22TRaz3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 6.Define Model Structure, Hyper Parameter Used in Training, Inference Function\n",
        "\n",
        "1. Need to change LAST_CKPT_PATH every time you train and set it to the latest checkpoint, which is presented by the biggest number in CHECKPOINT_PATH\n",
        "\n",
        "2. Keep other parameters as they are in the traning session, no need to change here"
      ]
    },
    {
      "metadata": {
        "id": "TBFHHe3tXLxC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# read checkpoint path, number indicates the latest step\n",
        "LAST_CKPT_PATH = \"ckpt-exp08/google-brain-gru-128size-7800\"\n",
        "\n",
        "# file for vocab\n",
        "SRC_VOCAB = \"vocab.en\"\n",
        "TRG_VOCAB = \"vocab.fr\"\n",
        "SRC_VOCAB_SIZE = vocab_size_src       \n",
        "TRG_VOCAB_SIZE = vocab_size_tgt \n",
        "\n",
        "# ID for <sos> and <eos> in vocab\n",
        "SOS_ID = 1\n",
        "EOS_ID = 2\n",
        "\n",
        "SHARE_EMB_AND_SOFTMAX = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "niye5X73s8IZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NMTModel(object):\n",
        "  \"\"\"\n",
        "  defind the nmt model\n",
        "  \n",
        "  \"\"\"\n",
        "  # define variables needed by nmt\n",
        "  def __init__(self, \n",
        "               dec_layer = DECODER_LAYERS, \n",
        "               enc_layer = ENCODER_LAYERS,\n",
        "               dec_cell_name = DECODER_CELL_TYPE, \n",
        "               enc_cell_name = ENCODER_CELL_TYPE,\n",
        "               optimizer = OPTIMIZER, \n",
        "               lr = LEARNING_RATE,\n",
        "               hid_size = HIDDEN_SIZE, \n",
        "               attention = ATTENTION,\n",
        "               drop_out = DROPOUT):\n",
        "    \n",
        "    self.dec_cell_name = dec_cell_name\n",
        "    self.enc_cell_name = enc_cell_name\n",
        "    self.dec_layer = dec_layer\n",
        "    self.enc_layer = enc_layer\n",
        "    self.attention = attention\n",
        "    \n",
        "    self.hid_size = hid_size\n",
        "    self.opt = optimizer\n",
        "    self.lr = lr\n",
        "    \n",
        "    self.keep_prob = 1.0 - drop_out\n",
        "\n",
        "    # EMBEDDING SETUP\n",
        "    \n",
        "    self.src_embedding = tf.get_variable(\n",
        "          \"src_emb\", [SRC_VOCAB_SIZE, self.hid_size])\n",
        "    self.trg_embedding = tf.get_variable(\n",
        "          \"trg_emb\", [TRG_VOCAB_SIZE, self.hid_size])\n",
        "\n",
        "      # define variables for softmax layer\n",
        "    if SHARE_EMB_AND_SOFTMAX:\n",
        "         self.softmax_weight = tf.transpose(self.trg_embedding)\n",
        "    else:\n",
        "         self.softmax_weight = tf.get_variable(\n",
        "             \"weight\", [self.hid_size, TRG_VOCAB_SIZE])\n",
        "    self.softmax_bias = tf.get_variable(\n",
        "          \"softmax_bias\", [TRG_VOCAB_SIZE])\n",
        "  \n",
        "  def inference(self, src_input):\n",
        "      # As dynamic rnn requires batch input, \n",
        "      # to infer one single sentence, we set batch = 1\n",
        "      src_size = tf.convert_to_tensor([len(src_input)], dtype=tf.int32)\n",
        "      src_input = tf.convert_to_tensor([src_input], dtype=tf.int32)\n",
        "      src_emb = tf.nn.embedding_lookup(self.src_embedding, src_input)\n",
        "      \n",
        "     \n",
        "      # *************************\n",
        "      # ***** ENCODER SCOPE *****\n",
        "      # *************************\n",
        "\n",
        "      with tf.variable_scope(\"encoder\"):\n",
        "        \n",
        "        if not 'bi' in self.enc_cell_name:\n",
        "        \n",
        "          enc_cell = multi_rnn_cell(self.enc_cell_name, \n",
        "                                    self.hid_size, \n",
        "                                    self.enc_layer, \n",
        "                                    self.keep_prob)\n",
        "          enc_outputs, enc_state = tf.nn.dynamic_rnn(enc_cell, \n",
        "                                                     inputs=src_emb, \n",
        "                                                     sequence_length=src_size, \n",
        "                                                     dtype=tf.float32) \n",
        "        \n",
        "        else:\n",
        "          \n",
        "          stacked_biRNN_fw, stacked_biRNN_bw = multi_biRNN_pair(self.enc_cell_name, \n",
        "                                                                self.hid_size, \n",
        "                                                                self.enc_layer, \n",
        "                                                                self.keep_prob)\n",
        "          enc_outputs, enc_state = tf.nn.bidirectional_dynamic_rnn(cell_fw = stacked_biRNN_fw,\n",
        "                                                                   cell_bw = stacked_biRNN_bw,\n",
        "                                                                   inputs = src_emb,\n",
        "                                                                   sequence_length = src_size,\n",
        "                                                                   dtype = tf.float32)\n",
        "          \n",
        "          # concatenate two outputs of LSTM cell as 1 tensor\n",
        "          # enc_outputs = (output_fw, output_bw)\n",
        "          enc_outputs = tf.concat([enc_outputs[0], enc_outputs[1]], -1)\n",
        "          \n",
        "    \n",
        "      # *************************\n",
        "      # ***** DECODER SCOPE *****\n",
        "      # *************************\n",
        "      \n",
        "      with tf.variable_scope(\"decoder\"):\n",
        "        \n",
        "        dec_cell = multi_rnn_cell(self.dec_cell_name, self.hid_size, self.dec_layer, self.keep_prob)\n",
        "    \n",
        "    \n",
        "        # OPTIONS FOR ATTENTION MECHANISM\n",
        "        if self.attention == 'Bahdanau':\n",
        "        \n",
        "          attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(\n",
        "                  self.hid_size, \n",
        "                  enc_outputs,\n",
        "                  memory_sequence_length = src_size)\n",
        "          \n",
        "        if self.attention == 'Luong':\n",
        "\n",
        "          attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n",
        "                  self.hid_size,\n",
        "                  enc_outputs,\n",
        "                  memory_sequence_length=src_size\n",
        "                  )\n",
        "\n",
        "        # ATTENTION WRAPPER: \n",
        "        # wrap dec_cell and attention mechanisim\n",
        "        attention_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
        "                dec_cell, \n",
        "                attention_mechanism,\n",
        "                attention_layer_size=self.hid_size,\n",
        "                alignment_history=True)\n",
        "\n",
        "      # Set the max step for decoder\n",
        "      MAX_DEC_LEN=100\n",
        "\n",
        "      with tf.variable_scope(\"decoder/rnn/attention_wrapper\"):\n",
        "        # use TensorArray store produced sentence\n",
        "        init_array = tf.TensorArray(dtype=tf.int32, size=0,\n",
        "            dynamic_size=True, clear_after_read=False)\n",
        "        # start input for decoder with <sos> tag\n",
        "        init_array = init_array.write(0, SOS_ID)\n",
        "        # initilize attention cell\n",
        "        init_loop_var = (\n",
        "            attention_cell.zero_state(batch_size=1, dtype=tf.float32),\n",
        "            init_array, 0)\n",
        "\n",
        "        # condition for tf.while_loop\n",
        "        # loop until decoder outputs <eos> or hit max length setting\n",
        "#         def continue_loop_condition(state, trg_ids, step):\n",
        "#             return tf.reduce_all(tf.logical_and(\n",
        "#                 tf.not_equal(trg_ids.read(step), EOS_ID),\n",
        "#                 tf.less(step, MAX_DEC_LEN-1),\n",
        "#                 tf.not_equal(trg_ids.read(step), trg_ids.read(step-1))))\n",
        "          \n",
        "        def continue_loop_condition(state, trg_ids, step):\n",
        "            return tf.reduce_all(tf.logical_and(\n",
        "                tf.not_equal(trg_ids.read(step), EOS_ID),\n",
        "                tf.less(step, MAX_DEC_LEN-1)))\n",
        "\n",
        "        def loop_body(state, trg_ids, step):\n",
        "          \n",
        "            # read last step output as input for attention cell\n",
        "            trg_input = [trg_ids.read(step)]\n",
        "            trg_emb = tf.nn.embedding_lookup(self.trg_embedding,\n",
        "                                             trg_input)\n",
        "            # FORWARD calc ATTENTION CELL and output decoder outputs/state\n",
        "            dec_outputs, next_state = attention_cell.call(\n",
        "                state=state, inputs=trg_emb)\n",
        "            \n",
        "            # calc logit for each candidate target vocab\n",
        "            # select the max as output\n",
        "            output = tf.reshape(dec_outputs, [-1, HIDDEN_SIZE])\n",
        "            logits = (tf.matmul(output, self.softmax_weight)\n",
        "                      + self.softmax_bias)\n",
        "            next_id = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
        "            # write output word into trg_ids\n",
        "            trg_ids = trg_ids.write(step+1, next_id[0])\n",
        "            return next_state, trg_ids, step+1\n",
        "\n",
        "        # execute tf.while_loop return trg_ides\n",
        "        state, trg_ids, step = tf.while_loop(\n",
        "            continue_loop_condition, loop_body, init_loop_var)\n",
        "        \n",
        "        return trg_ids.stack(), state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QkwNGGt0kvcp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 7. Test and Evaluate"
      ]
    },
    {
      "metadata": {
        "id": "1zFqa6lcp9n_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "def levenshtein(seq1, seq2):  \n",
        "    size_x = len(seq1) + 1\n",
        "    size_y = len(seq2) + 1\n",
        "    matrix = np.zeros ((size_x, size_y))\n",
        "    for x in range(size_x):\n",
        "        matrix [x, 0] = x\n",
        "    for y in range(size_y):\n",
        "        matrix [0, y] = y\n",
        "\n",
        "    for x in range(1, size_x):\n",
        "        for y in range(1, size_y):\n",
        "            if seq1[x-1] == seq2[y-1]:\n",
        "                matrix [x,y] = min(\n",
        "                    matrix[x-1, y] + 1,\n",
        "                    matrix[x-1, y-1],\n",
        "                    matrix[x, y-1] + 1\n",
        "                )\n",
        "            else:\n",
        "                matrix [x,y] = min(\n",
        "                    matrix[x-1,y] + 1,\n",
        "                    matrix[x-1,y-1] + 1,\n",
        "                    matrix[x,y-1] + 1\n",
        "                )\n",
        "\n",
        "    return matrix[size_x - 1, size_y - 1]\n",
        "\n",
        "def translate_en_fr(src_sent, trgt_sent, plot_att = False, verbose = False):\n",
        "    \n",
        "    tf.reset_default_graph()\n",
        "        \n",
        "    # define the trained model\n",
        "    with tf.variable_scope(\"nmt_model\", reuse=None):\n",
        "        model = NMTModel()\n",
        "       \n",
        "    # convert sentence to word_index according to vocab\n",
        "    with codecs.open(SRC_VOCAB, \"r\", \"utf-8\") as f_vocab:\n",
        "        src_vocab = [w.strip() for w in f_vocab.readlines()]\n",
        "        src_id_dict = dict((src_vocab[x], x) for x in range(len(src_vocab)))\n",
        "    test_en_ids = [(src_id_dict[token] if token in src_id_dict else src_id_dict['<unk>'])\n",
        "                   for token in src_sent.split()]\n",
        "    print('target sentence id: {}'.format(test_en_ids))\n",
        "\n",
        "    # build inference based on saved model weights\n",
        "    output_op, state_op = model.inference(test_en_ids)\n",
        "    sess = tf.Session()\n",
        "    saver = tf.train.Saver()\n",
        "    saver.restore(sess, LAST_CKPT_PATH)\n",
        "\n",
        "    # read translation output\n",
        "    output_ids = sess.run(output_op)\n",
        "    print('target sentence id: {}'.format(output_ids))\n",
        "    \n",
        "    # convert translation idx into word\n",
        "    with codecs.open(TRG_VOCAB, \"r\", \"utf-8\") as f_vocab:\n",
        "        trg_vocab = [w.strip() for w in f_vocab.readlines()]\n",
        "    output_text = ' '.join([trg_vocab[x] for x in output_ids])\n",
        "    \n",
        "    # output translation\n",
        "    final_output_text = output_text.encode('utf8').decode(sys.stdout.encoding).strip('<eos>')\n",
        "    \n",
        "    bleu = sentence_bleu(trgt_sent.split(), final_output_text.split())\n",
        "    lst = levenshtein(trgt_sent,final_output_text)\n",
        "    \n",
        "    if verbose:\n",
        "      print(\"Source Sentence: \" + src_sent)\n",
        "      print(\"Real Translation: \" + trgt_sent)\n",
        "      print(\"Predicted Translation: \" + final_output_text)\n",
        "      print(\"Levenshetein Distance: \" + str(lst))\n",
        "      print(\"***BLEU Score***: \"+ str(bleu))\n",
        "    \n",
        "    \n",
        "    # PLOT ATTENTION PLOT OPTION\n",
        "    \n",
        "    def plot_attention(attention, src_sent, pred_sent):\n",
        "\n",
        "      fig = plt.figure(figsize=(10,10))\n",
        "      ax = fig.add_subplot(1, 1, 1)\n",
        "      ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "      fontdict = {'fontsize': 14}\n",
        "      \n",
        "      ax.set_xticks(np.arange(len(list(src_sent.split()))))\n",
        "      ax.set_yticks(np.arange(len(list(pred_sent.split()))))\n",
        "\n",
        "      ax.set_xticklabels([''] + list(src_sent.split()), fontdict=fontdict, rotation=90)\n",
        "      ax.set_yticklabels([''] + list(pred_sent.split()), fontdict=fontdict)\n",
        "\n",
        "      plt.show()\n",
        "      \n",
        "    if plot_att:\n",
        "      alignments = sess.run(state_op.alignment_history.stack())\n",
        "      alignments = np.squeeze(alignments)\n",
        "      plot_attention(alignments, src_sent, final_output_text)\n",
        "      \n",
        "    return final_output_text, bleu, lst\n",
        "    \n",
        "    sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0EBBf2D8z08T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# prediction for total test set\n",
        "\n",
        "def test_set_pred(src_test, tgt_test, verbose = False):\n",
        "  src_test = src_test\n",
        "  tgt_test = tgt_test\n",
        " \n",
        "  size = len(src_test)\n",
        "  \n",
        "  pred_list = []\n",
        "  bleu_list = []\n",
        "  lst_list = []\n",
        "\n",
        "  for i in range(size):\n",
        "\n",
        "      pred, bleu, lst = translate_en_fr(src_test[i], tgt_test[i], verbose = verbose)\n",
        "      print(\"                                                                                         \")\n",
        "      pred_list.append(pred)\n",
        "      bleu_list.append(bleu)\n",
        "      lst_list.append(lst)\n",
        "      \n",
        "      \n",
        "  c_bleu = sum(bleu_list) / len(bleu_list)\n",
        "  c_lst = sum(lst_list) / len(lst_list)  \n",
        "   \n",
        "  print(\"                                                                                         \")\n",
        "  print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
        "  print(\"Prediction Output and Metrics on {} test sentences: \".format(size))\n",
        "  print(\"Average BLEU Score on our test corpus is {}\".format(c_bleu)) \n",
        "  print(\"Average Levenshetein distance Score on our test corpus is {}\".format(c_lst)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "N6vrY1_RkRlG"
      },
      "cell_type": "markdown",
      "source": [
        "### 3. Test"
      ]
    },
    {
      "metadata": {
        "id": "LByUsIb2xnAJ",
        "colab_type": "code",
        "outputId": "eaf814ed-ba48-4f58-85d1-91fc007afc4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1155
        }
      },
      "cell_type": "code",
      "source": [
        "src_sent = 'comment on the misappropriation of bibliographical references in science . the example of anti aging medicine'\n",
        "tgt_sent = 'du detournement des references bibliographiques en science . l exemple de la medecine anti age '\n",
        "\n",
        "\n",
        "translate_en_fr(src_sent,\n",
        "                tgt_sent, \n",
        "                verbose = True,\n",
        "                plot_att = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "target sentence id: [1805, 16, 5, 15332, 4, 11235, 6853, 6, 939, 12, 5, 363, 4, 197, 454, 61]\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from ckpt-exp08/google-brain-gru-128size-7800\n",
            "target sentence id: [   1  330   27   14 1471    4    5 5311    4    5  499   18   14  740\n",
            "    4    5  229    4    5   36    4  850   19    5  238    4    5   53\n",
            "    4    5   53    4    5  229    4    5   53    4    5  229    4    5\n",
            "  229    4    5   53    4    5  229    4    5  725    4    5   53   19\n",
            "    4    7  397    4    5  229    4    5  229    4    5   53    4    5\n",
            "   53    4    5   53    4    5  229   19    4    5  229    4    5  229\n",
            "    4    5   53    4    5  229    4    5  157    4    5  499   19   19\n",
            "   19   19]\n",
            "Source Sentence: comment on the misappropriation of bibliographical references in science . the example of anti aging medicine\n",
            "Real Translation: du detournement des references bibliographiques en science . l exemple de la medecine anti age \n",
            "Predicted Translation:  pourquoi sur les performances de la nevralgie de la main dans les sciences de la societe de la maladie de parkinson . la exemple de la medecine de la medecine de la societe de la medecine de la societe de la societe de la medecine de la societe de la transmission de la medecine . de l article de la societe de la societe de la medecine de la medecine de la medecine de la societe . de la societe de la societe de la medecine de la societe de la douleur de la main . . . .\n",
            "Levenshetein Distance: 399.0\n",
            "***BLEU Score***: 0.3770063804549471\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAANMAAAK1CAYAAABSNdu3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUxC0iAimIGgREUxB0CL+Pw4zAyKi8iIdAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(' pourquoi sur les performances de la nevralgie de la main dans les sciences de la societe de la maladie de parkinson . la exemple de la medecine de la medecine de la societe de la medecine de la societe de la societe de la medecine de la societe de la transmission de la medecine . de l article de la societe de la societe de la medecine de la medecine de la medecine de la societe . de la societe de la societe de la medecine de la societe de la douleur de la main . . . .',\n",
              " 0.3770063804549471,\n",
              " 399.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "w_s-FWPSlZyv",
        "colab_type": "code",
        "outputId": "63894608-8ac4-4d2e-ac47-6bd2fa10865a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "cell_type": "code",
      "source": [
        "test_set_pred(src_test, tgt_test, verbose = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "target sentence id: [171, 262, 4, 61, 6, 4303]\n",
            "INFO:tensorflow:Restoring parameters from ckpt-exp08/google-brain-gru-128size-7800\n",
            "target sentence id: [  1 112   4   5  68   4  53   4   7  34  12  57   2]\n",
            "Source Sentence:  current state of medicine in spain \n",
            "Real Translation:  etat actuel de la medecine en espagne \n",
            "Predicted Translation:  etat de la pratique de medecine de l enfant en france \n",
            "Levenshetein Distance: 29.0\n",
            "***BLEU Score***: 0.5491004867761125\n",
            "                                                                                         \n",
            "target sentence id: [204, 11, 5, 29, 4, 1201, 4, 5, 2573]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ckpt-exp08/google-brain-gru-128size-7800\n",
            "target sentence id: [  1 887  10   7  32   8 937   4   7  79   4   7 309   2]\n",
            "Source Sentence:  contribution to the study of accidents of the teeth \n",
            "Real Translation:  contribution a l etude des accidents de la dentition \n",
            "Predicted Translation:  contribution a l etude des examens de l analyse de l asthme \n",
            "Levenshetein Distance: 21.0\n",
            "***BLEU Score***: 0.6389431042462724\n",
            "                                                                                         \n",
            "target sentence id: [47, 4, 3961, 67]\n",
            "INFO:tensorflow:Restoring parameters from ckpt-exp08/google-brain-gru-128size-7800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rAThnX-bczYN",
        "colab_type": "code",
        "outputId": "176ae13e-537d-438e-c425-a7ccfc32a3de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 878
        }
      },
      "cell_type": "code",
      "source": [
        "src_sent = 'myositis ossificans in a young child '\n",
        "tgt_sent = 'myosite ossifiante chez un jeune enfant'\n",
        "\n",
        "\n",
        "translate_en_fr(src_sent,\n",
        "                tgt_sent, \n",
        "                verbose = True,\n",
        "                plot_att = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "target sentence id: [2938, 6375, 6, 8, 195, 83]\n",
            "INFO:tensorflow:Restoring parameters from ckpt-exp08/google-brain-gru-128size-7800\n",
            "target sentence id: [  1  15  24   4  96   4  96  22  16 321 321 321  22  16 321 321  22  16\n",
            " 321 321 321 321   2]\n",
            "Source Sentence: myositis ossificans in a young child \n",
            "Real Translation: myosite ossifiante chez un jeune enfant\n",
            "Predicted Translation:  le cas de type de type chez un jeune jeune jeune chez un jeune jeune chez un jeune jeune jeune jeune \n",
            "Levenshetein Distance: 78.0\n",
            "***BLEU Score***: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMcAAAJ9CAYAAACBy2b8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmGU4HGYZDodZhsNhlvH/ARv/zNZd8lmnAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(' le cas de type de type chez un jeune jeune jeune chez un jeune jeune chez un jeune jeune jeune jeune ',\n",
              " 0,\n",
              " 78.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "X7tZKnyV4_J0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}